# Source Code Structure

## ğŸ“ Folder Organization

### `preprocessing/`
Contains data preprocessing and cleaning utilities.

**Files:**
- `data_loader.py` - Load raw data, prepare it, and split into train/test sets
- `text_cleaner.py` - Clean and preprocess text data (remove URLs, mentions, etc.)

**Key Classes:**
- `DataLoader` - Handles data loading, preparation, and splitting
- `TextCleaner` - Cleans text data for model training

### `features/`
Contains feature engineering modules.

**Files:**
- `text_features.py` - Extract text-based features (length, hashtags, emojis, etc.)
- `engagement_features.py` - Extract engagement-related features

**Key Classes:**
- `TextFeatureExtractor` - Extracts 15+ text features including:
  - Text length, word count, line count
  - Hashtag count, emoji count, URL count
  - Call-to-action detection
  - Question detection
  - Punctuation features
  
- `EngagementFeatureExtractor` - Calculates engagement metrics:
  - Weighted engagement score
  - Engagement ratios (comment/like, share/like, etc.)
  - Engagement intensity

### `models/`
Contains trained models and vectorizers (generated by notebooks).

**Expected Files:**
- `engagement_model.pkl` - Trained Random Forest model
- `tfidf_vectorizer.pkl` - Fitted TF-IDF vectorizer

## ğŸš€ Usage

### Process Raw Data

Run the data processing pipeline to generate processed datasets:

```bash
python src/data_processing_pipeline.py
```

This will:
1. Load raw data from `data/raw/LinkedIN_Caption_DataSet.xlsx`
2. Calculate engagement scores
3. Extract text features
4. Extract engagement features
5. Save processed data to `data/processed/`

### Use in Notebooks

```python
from src.preprocessing import DataLoader, TextCleaner
from src.features import TextFeatureExtractor, EngagementFeatureExtractor

# Load data
loader = DataLoader('data/raw/LinkedIN_Caption_DataSet.xlsx')
df = loader.load_raw_data()

# Extract features
text_extractor = TextFeatureExtractor()
features = text_extractor.extract_features("Your LinkedIn post text here")
```

### Use in API

```python
from src.features import TextFeatureExtractor

# In your Flask API
extractor = TextFeatureExtractor()
features = extractor.extract_features(post_text)
```

## ğŸ“Š Data Flow

```
Raw Data (Excel)
    â†“
DataLoader (load & prepare)
    â†“
TextCleaner (optional cleaning)
    â†“
Feature Extractors (text + engagement)
    â†“
Processed Data (CSV)
    â†“
Model Training (notebooks)
    â†“
Saved Models (pkl files)
    â†“
API Predictions
```

## ğŸ”§ Key Features Extracted

### Text Features (15+)
- `text_length` - Total character count
- `word_count` - Number of words
- `line_count` - Number of lines
- `avg_word_length` - Average word length
- `exclamation_count` - Number of exclamation marks
- `question_count` - Number of question marks
- `emoji_count` - Number of emojis
- `hashtag_count` - Number of hashtags
- `url_count` - Number of URLs
- `mention_count` - Number of @mentions
- `has_cta` - Has call-to-action (0/1)
- `has_question` - Contains question (0/1)
- `uppercase_ratio` - Ratio of uppercase letters

### Engagement Features
- `total_engagement` - Weighted sum: likes + (2Ã—comments) + (3Ã—shares)
- `comment_like_ratio` - Comments per like
- `share_like_ratio` - Shares per like
- `share_comment_ratio` - Shares per comment
- `engagement_intensity` - (Comments + Shares) / Likes

## ğŸ“ Notes

- All modules are designed to be reusable and modular
- Feature extractors can be used independently or together
- Data processing pipeline can be customized by modifying the script
- Models are saved in `src/models/` after training in notebooks
