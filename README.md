# LinkedIn Post Intelligence System

A data-driven system to analyze LinkedIn post captions and predict engagement potential.

## Setup Instructions

### 1. Virtual Environment
A virtual environment has been created in the `venv` folder.

### 2. Activate Virtual Environment
```bash
# On Windows
.\venv\Scripts\activate

# On Linux/Mac
source venv/bin/activate
```

### 3. Install Dependencies
All required libraries are already installed. If you need to reinstall:
```bash
pip install -r requirements.txt
```

### 4. Run the Notebook
```bash
jupyter notebook notebooks/02_engagement_prediction_model.ipynb
```

## Project Structure
- `data/raw/` - Contains the LinkedIn dataset (LinkedIN_Caption_DataSet.xlsx)
- `data/processed/` - Processed datasets (generated by pipeline)
  - `processed_data.csv` - Full processed dataset with features
  - `train_data.csv` - Training set (80%)
  - `test_data.csv` - Test set (20%)
- `notebooks/` - Jupyter notebooks for analysis and modeling
  - `01_data_preparation.ipynb` - Data exploration
  - `02_engagement_prediction_model.ipynb` - Model training & evaluation
- `src/` - Source code modules
  - `preprocessing/` - Data loading and cleaning utilities
  - `features/` - Feature engineering modules
  - `models/` - Saved models and vectorizers
- `frontend/` - Web interface
  - `index.html` - Home page
  - `analysis.html` - Post analysis page
  - `about.html` - About page
  - `css/styles.css` - Styling with gradients and animations
  - `js/script.js` - API integration and interactions
- `api/` - Backend API (to be created)
- `requirements.txt` - All Python dependencies with exact versions

## ðŸš€ Quick Start

### 1. Setup Environment
```bash
# Activate virtual environment
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies (already installed)
pip install -r requirements.txt
```

### 2. Process Data
```bash
# Run data processing pipeline
python src/data_processing_pipeline.py
```

This will generate:
- `data/processed/processed_data.csv` - Full dataset with 15+ features
- `data/processed/train_data.csv` - Training set
- `data/processed/test_data.csv` - Test set

### 3. Train Model
```bash
# Open and run the notebook
jupyter notebook notebooks/02_engagement_prediction_model.ipynb
```

### 4. Launch Frontend
Open `frontend/index.html` in your browser to see the beautiful UI!

## ðŸ“Š Features Extracted

The data processing pipeline extracts 15+ features:

**Text Features:**
- Text length, word count, line count
- Hashtag count, emoji count, URL count
- Call-to-action detection
- Question detection
- Punctuation analysis

**Engagement Features:**
- Weighted engagement score
- Comment/like ratio
- Share/like ratio
- Engagement intensity

## Model Features
- Predicts engagement scores (High/Medium/Low) based on post content
- Identifies which content lines drive engagement predictions
- Uses Random Forest classifier with TF-IDF features
- Provides line-by-line content attribution analysis with impact scores
- Visualizes feature importance and model performance

## Dataset
The dataset contains 2,500 LinkedIn posts with:
- Post content/text
- Likes, comments, and shares metrics
- Engagement calculated as: likes + (2 Ã— comments) + (3 Ã— shares)
